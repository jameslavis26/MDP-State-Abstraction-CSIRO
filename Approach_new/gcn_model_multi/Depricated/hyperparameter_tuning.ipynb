{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MDP_helpers import calculate_gap\n",
    "from dataset import MDPDataset, AllNodeFeatures, InMemoryMDPDataset, TransitionsOnEdge\n",
    "from generate_mdps import generate_datsets\n",
    "from experiment import Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn.models import GCN, GAT\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torch.utils.data import random_split\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "from time import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.manual_seed(12345)\n",
    "np.random.seed(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# device='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_states: 243\n",
      "Deleting folder  datasets/hparam_data/raw\n",
      "Generating 100 MDPs with 243 states and 5 actions \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:19<00:00,  5.03it/s]\n"
     ]
    }
   ],
   "source": [
    "N_datasets = 100\n",
    "\n",
    "N_sites = 5\n",
    "N_species = 20\n",
    "K = 7\n",
    "\n",
    "N_states = 3**N_sites\n",
    "print(f\"N_states: {N_states}\")\n",
    "generate_datsets(N_sites, N_species, K, N_datasets, remove_previous=False, folder=\"hparam_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = InMemoryMDPDataset(f\"datasets/mdp_{N_states}_state\", pre_transform=TransitionsOnEdge())\n",
    "dataset = InMemoryMDPDataset(f\"datasets/mdp_{N_states}_state\", pre_transform=AllNodeFeatures())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.all(dataset[0].R == dataset[5].R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_split = int(len(dataset)*0.8)\n",
    "train_data = dataset[:data_split]\n",
    "test_data = dataset[data_split:]\n",
    "\n",
    "hparam_split = int(len(train_data)*0.8)\n",
    "train_data_hparam = train_data[:hparam_split]\n",
    "val_data = train_data[hparam_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ExponentialLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-01 18:01:19,532] A new study created in memory with name: no-name-325fa119-e223-45cf-b3a6-552d097f2aad\n",
      "[I 2023-11-01 18:01:36,260] Trial 0 finished with value: 0.3650246668315851 and parameters: {'hidden_channels': 186, 'dropout': 0.015995434981939807, 'lr': 2.734393372431539, 'weight_decay': 0.0031204553909045256, 'gamma': 0.9540675060228595}. Best is trial 0 with value: 0.3650246668315851.\n",
      "[I 2023-11-01 18:01:52,010] Trial 1 finished with value: 0.6003516783212614 and parameters: {'hidden_channels': 170, 'dropout': 0.03718399312608728, 'lr': 6.256611530360379, 'weight_decay': 0.01067138133398014, 'gamma': 0.970472237538076}. Best is trial 1 with value: 0.6003516783212614.\n",
      "[I 2023-11-01 18:02:08,639] Trial 2 finished with value: 0.6395676311156622 and parameters: {'hidden_channels': 195, 'dropout': 0.01405175681230887, 'lr': 2.656559835518944, 'weight_decay': 0.004537985683567207, 'gamma': 0.9885185131486003}. Best is trial 2 with value: 0.6395676311156622.\n",
      "[I 2023-11-01 18:02:25,257] Trial 3 finished with value: 0.46874657861051117 and parameters: {'hidden_channels': 207, 'dropout': 0.04094061647344024, 'lr': 4.107161092319579, 'weight_decay': 0.002537820991286511, 'gamma': 0.996462421973205}. Best is trial 2 with value: 0.6395676311156622.\n",
      "[I 2023-11-01 18:02:41,012] Trial 4 finished with value: 0.42301570964683655 and parameters: {'hidden_channels': 184, 'dropout': 0.01628431677050517, 'lr': 5.884001066191932, 'weight_decay': 0.03629175580045538, 'gamma': 0.9885887286535939}. Best is trial 2 with value: 0.6395676311156622.\n",
      "[I 2023-11-01 18:02:57,462] Trial 5 finished with value: 0.6283328904680908 and parameters: {'hidden_channels': 157, 'dropout': 0.0031888248977720193, 'lr': 5.9387477977534955, 'weight_decay': 0.006206002627844334, 'gamma': 0.969820214868032}. Best is trial 2 with value: 0.6395676311156622.\n",
      "[I 2023-11-01 18:03:13,210] Trial 6 finished with value: 0.43076728383547047 and parameters: {'hidden_channels': 194, 'dropout': 0.021945107967377, 'lr': 7.408064380130946, 'weight_decay': 0.02742881389712307, 'gamma': 0.9779455290560883}. Best is trial 2 with value: 0.6395676311156622.\n",
      "[I 2023-11-01 18:03:28,976] Trial 7 finished with value: 0.43415105564333967 and parameters: {'hidden_channels': 152, 'dropout': 0.024294483721137423, 'lr': 6.091918716343553, 'weight_decay': 0.029267392466374432, 'gamma': 0.9747978150070671}. Best is trial 2 with value: 0.6395676311156622.\n",
      "[I 2023-11-01 18:03:44,597] Trial 8 finished with value: 0.3947016532518677 and parameters: {'hidden_channels': 186, 'dropout': 0.014043548684642006, 'lr': 6.889191170236086, 'weight_decay': 0.03732123816296822, 'gamma': 0.9639977327630259}. Best is trial 2 with value: 0.6395676311156622.\n",
      "[I 2023-11-01 18:04:00,394] Trial 9 finished with value: 0.35157029988171784 and parameters: {'hidden_channels': 152, 'dropout': 0.019506271086133793, 'lr': 6.2643456586583515, 'weight_decay': 0.03798252179954639, 'gamma': 0.9604472678865259}. Best is trial 2 with value: 0.6395676311156622.\n",
      "[I 2023-11-01 18:04:15,975] Trial 10 finished with value: 0.5504923553613581 and parameters: {'hidden_channels': 223, 'dropout': 0.00033248629939870017, 'lr': 2.16856472164149, 'weight_decay': 0.013531872361067232, 'gamma': 0.9998152866144812}. Best is trial 2 with value: 0.6395676311156622.\n",
      "[I 2023-11-01 18:04:31,628] Trial 11 finished with value: 0.6056746336998385 and parameters: {'hidden_channels': 205, 'dropout': 0.004916984754919491, 'lr': 4.725411535144621, 'weight_decay': 0.009293865481114966, 'gamma': 0.9825631910887825}. Best is trial 2 with value: 0.6395676311156622.\n",
      "[I 2023-11-01 18:04:47,080] Trial 12 finished with value: 0.4238179107561124 and parameters: {'hidden_channels': 169, 'dropout': 0.008281833073700198, 'lr': 3.6658645481403416, 'weight_decay': 0.01689623524291627, 'gamma': 0.9897200043651943}. Best is trial 2 with value: 0.6395676311156622.\n",
      "[I 2023-11-01 18:05:02,539] Trial 13 finished with value: 0.6297434880607907 and parameters: {'hidden_channels': 168, 'dropout': 0.007804878726052001, 'lr': 5.013909607362791, 'weight_decay': 0.0070571362839210615, 'gamma': 0.9686209185695251}. Best is trial 2 with value: 0.6395676311156622.\n",
      "[I 2023-11-01 18:05:19,039] Trial 14 finished with value: 0.4696043427892096 and parameters: {'hidden_channels': 172, 'dropout': 0.011408915884069726, 'lr': 4.899643902755632, 'weight_decay': 0.0014540402519180526, 'gamma': 0.9851619127227521}. Best is trial 2 with value: 0.6395676311156622.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6395676311156622\n",
      "{'hidden_channels': 195, 'dropout': 0.01405175681230887, 'lr': 2.656559835518944, 'weight_decay': 0.004537985683567207, 'gamma': 0.9885185131486003}\n"
     ]
    }
   ],
   "source": [
    "N_epochs = 500\n",
    "\n",
    "def objective(trial):\n",
    "    hidden_channels = trial.suggest_int(\"hidden_channels\", 150, 225)\n",
    "    num_layers = 1#trial.suggest_int(\"num_layers\", 1, 3)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0, 0.05)\n",
    "    lr = trial.suggest_float(\"lr\", 2, 8)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-3, 0.04)\n",
    "\n",
    "    gamma = trial.suggest_float(\"gamma\", 0.95, 1)\n",
    "\n",
    "    gcn_model = GCN(\n",
    "        in_channels=dataset[0].x.shape[1], \n",
    "        out_channels=K, \n",
    "        hidden_channels=hidden_channels, \n",
    "        num_layers=num_layers, \n",
    "        dropout=dropout\n",
    "    ).to(device)\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.Adam(gcn_model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "    lr_sheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma)\n",
    "\n",
    "    gcn_model.train()\n",
    "    for epoch in range(N_epochs):\n",
    "        optimizer.zero_grad()     \n",
    "        loss = 0\n",
    "        for data in train_data_hparam:\n",
    "            pred = gcn_model(\n",
    "                x = data.x.to(device), \n",
    "                edge_index=data.edges.to(device), \n",
    "                # edge_attr=edge_features\n",
    "            )\n",
    "            loss += loss_function(pred, data.k_labels.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_sheduler.step()\n",
    "    \n",
    "    gcn_model.eval()\n",
    "    errors = []\n",
    "    recall = []\n",
    "    for data in val_data:\n",
    "        out = gcn_model(\n",
    "                x = data.x.to(device), \n",
    "                edge_index=data.edges.to(device), \n",
    "                # edge_attr=edge_features\n",
    "            )\n",
    "        pred = F.softmax(out, dim=1).argmax(axis=1)#.to('cpu')\n",
    "\n",
    "        _, error = calculate_gap(data.P, data.R, data.V, pred, K, device=device)\n",
    "        errors.append(error.to('cpu'))\n",
    "        recall.append(\n",
    "            recall_score(data.k_labels.to('cpu'), pred.to('cpu'), average=\"macro\")\n",
    "        )\n",
    "    \n",
    "    return np.mean(recall) - np.mean(errors) # Minimise errors while maximising recall score\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=15, n_jobs=1)\n",
    "\n",
    "best_params = study.best_params\n",
    "\n",
    "print(study.best_value)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "trials = [i for i in map(lambda x: dict([(\"score\", x.values[0]),*(x.params).items()]), study.get_trials())]\n",
    "trials = pd.DataFrame(trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "score\thidden_channels\tnum_layers\tdropout\tlr\tweight_decay\tweight_param\tgamma\n",
    "21\t0.403245\t67\t1\t0.051031\t4.809483\t0.045045\t8\t0.972926\n",
    "20\t0.403374\t63\t1\t0.003532\t4.839212\t0.040630\t8\t0.989183\n",
    "14\t1.023662\t19\t1\t0.295559\t5.025916\t0.053842\t7\t0.798589"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>hidden_channels</th>\n",
       "      <th>dropout</th>\n",
       "      <th>lr</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>gamma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.599886</td>\n",
       "      <td>189</td>\n",
       "      <td>0.030787</td>\n",
       "      <td>3.640513</td>\n",
       "      <td>0.008176</td>\n",
       "      <td>0.989859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.572620</td>\n",
       "      <td>151</td>\n",
       "      <td>0.030954</td>\n",
       "      <td>2.301565</td>\n",
       "      <td>0.004388</td>\n",
       "      <td>0.984601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.527417</td>\n",
       "      <td>170</td>\n",
       "      <td>0.027613</td>\n",
       "      <td>7.781805</td>\n",
       "      <td>0.011654</td>\n",
       "      <td>0.985464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.518439</td>\n",
       "      <td>174</td>\n",
       "      <td>0.026031</td>\n",
       "      <td>7.728138</td>\n",
       "      <td>0.010252</td>\n",
       "      <td>0.980316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.496078</td>\n",
       "      <td>172</td>\n",
       "      <td>0.023114</td>\n",
       "      <td>7.176134</td>\n",
       "      <td>0.002211</td>\n",
       "      <td>0.965279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.469434</td>\n",
       "      <td>156</td>\n",
       "      <td>0.040329</td>\n",
       "      <td>3.638957</td>\n",
       "      <td>0.001374</td>\n",
       "      <td>0.994972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.458307</td>\n",
       "      <td>216</td>\n",
       "      <td>0.025998</td>\n",
       "      <td>6.629531</td>\n",
       "      <td>0.025800</td>\n",
       "      <td>0.997925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.455355</td>\n",
       "      <td>209</td>\n",
       "      <td>0.034853</td>\n",
       "      <td>5.428958</td>\n",
       "      <td>0.002279</td>\n",
       "      <td>0.997370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.433783</td>\n",
       "      <td>150</td>\n",
       "      <td>0.013130</td>\n",
       "      <td>6.859550</td>\n",
       "      <td>0.028589</td>\n",
       "      <td>0.967631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.427670</td>\n",
       "      <td>157</td>\n",
       "      <td>0.036784</td>\n",
       "      <td>2.719543</td>\n",
       "      <td>0.031845</td>\n",
       "      <td>0.974796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.426803</td>\n",
       "      <td>166</td>\n",
       "      <td>0.031836</td>\n",
       "      <td>4.476059</td>\n",
       "      <td>0.014521</td>\n",
       "      <td>0.985426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.422717</td>\n",
       "      <td>215</td>\n",
       "      <td>0.037440</td>\n",
       "      <td>5.201777</td>\n",
       "      <td>0.037749</td>\n",
       "      <td>0.996359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.408912</td>\n",
       "      <td>195</td>\n",
       "      <td>0.005684</td>\n",
       "      <td>2.223735</td>\n",
       "      <td>0.012989</td>\n",
       "      <td>0.953747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.392643</td>\n",
       "      <td>179</td>\n",
       "      <td>0.016326</td>\n",
       "      <td>6.566137</td>\n",
       "      <td>0.032298</td>\n",
       "      <td>0.965245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.287610</td>\n",
       "      <td>152</td>\n",
       "      <td>0.046202</td>\n",
       "      <td>6.345946</td>\n",
       "      <td>0.025715</td>\n",
       "      <td>0.996757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       score  hidden_channels   dropout        lr  weight_decay     gamma\n",
       "14  0.599886              189  0.030787  3.640513      0.008176  0.989859\n",
       "2   0.572620              151  0.030954  2.301565      0.004388  0.984601\n",
       "12  0.527417              170  0.027613  7.781805      0.011654  0.985464\n",
       "11  0.518439              174  0.026031  7.728138      0.010252  0.980316\n",
       "5   0.496078              172  0.023114  7.176134      0.002211  0.965279\n",
       "7   0.469434              156  0.040329  3.638957      0.001374  0.994972\n",
       "4   0.458307              216  0.025998  6.629531      0.025800  0.997925\n",
       "8   0.455355              209  0.034853  5.428958      0.002279  0.997370\n",
       "1   0.433783              150  0.013130  6.859550      0.028589  0.967631\n",
       "3   0.427670              157  0.036784  2.719543      0.031845  0.974796\n",
       "13  0.426803              166  0.031836  4.476059      0.014521  0.985426\n",
       "6   0.422717              215  0.037440  5.201777      0.037749  0.996359\n",
       "10  0.408912              195  0.005684  2.223735      0.012989  0.953747\n",
       "9   0.392643              179  0.016326  6.566137      0.032298  0.965245\n",
       "0   0.287610              152  0.046202  6.345946      0.025715  0.996757"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials.sort_values(by=\"score\", ascending=False)#.plot.scatter(x=\"weight_decay\", y=\"score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment = Experiment(savefile=\"gat_hparams\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in trials.index:\n",
    "#     trials.loc[i].to_dict()\n",
    "    # experiment.save(trials.loc[i].to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f50ed3b5ee24e8ebac96f2a320b6a529fb0cbd6f6197cf3a5968f4ecab23d005"
  },
  "kernelspec": {
   "display_name": "Python 3.10.12 ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
