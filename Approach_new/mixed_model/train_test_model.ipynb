{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "from generate_mdps import generate_datsets\n",
    "from dataset import MDPDataset, AllNodeFeatures, InMemoryMDPDataset, TransitionsOnEdge\n",
    "from experiment import Experiment\n",
    "from MDP_helpers import calculate_gap, multiclass_recall_score\n",
    "\n",
    "# %%\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn.models import GCN, GAT\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torch.utils.data import random_split\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import recall_score, accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.cuda.manual_seed(12345)\n",
    "np.random.seed(12345)\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device='cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs\n",
    "experiment_name = \"GCN_GCN\"\n",
    "hparam_file = \"hparams\"\n",
    "ascending = True\n",
    "edge_attributes = True\n",
    "model_1 = GCN\n",
    "model_2 = GCN\n",
    "pre_transform = AllNodeFeatures()\n",
    "lr = 0.001\n",
    "N_epochs = 3000\n",
    "N_epochs_H = 3000\n",
    "\n",
    "N_datasets = 100\n",
    "\n",
    "N_sites = 5\n",
    "N_species = 20\n",
    "K = 7\n",
    "N_states = 3**N_sites\n",
    "\n",
    "recreate_data = False\n",
    "N_trials = 5\n",
    "\n",
    "train_ratio = 0.8\n",
    "test_ratio = 1-train_ratio\n",
    "\n",
    "filename = f'Reserve_MDP_{N_states}_{K}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MDP Data: N_states: {N_states}\")\n",
    "dataset_folder = f\"Reserve_MDP_{N_states}_{K}\"\n",
    "generate_datsets(N_sites, N_species, K, N_datasets, remove_previous=recreate_data, folder=dataset_folder)\n",
    "\n",
    "print(\"Loading data into dataloader\")\n",
    "print(pre_transform)\n",
    "dataset = InMemoryMDPDataset(f\"datasets/{dataset_folder}\", pre_transform=pre_transform)\n",
    "print(dataset[0])\n",
    "if torch.all(dataset[0].R == dataset[5].R):\n",
    "    raise Exception(\"Datasets are likely identical!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(train_ratio * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "h_param_size = int(train_ratio*train_size)\n",
    "val_size = train_size - h_param_size\n",
    "\n",
    "train_set, test_set = random_split(dataset, [train_size, test_size])\n",
    "hparam_train_set, hparam_val_set = random_split(train_set, [h_param_size, val_size])\n",
    "\n",
    "train_data = DataLoader(train_set, batch_size=1, shuffle=True)\n",
    "test_data = DataLoader(test_set, batch_size=1, shuffle=True)\n",
    "hparam_train_data = DataLoader(hparam_train_set, batch_size=1, shuffle=True)\n",
    "hparam_val_data = DataLoader(hparam_val_set, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(logits, target, V, mask, weights, lam, mu):\n",
    "    targets_one_hot = torch.zeros(target.size(0), K)\n",
    "    targets_one_hot.scatter_(1, target.unsqueeze(1), 1.0)\n",
    "\n",
    "    probs = (torch.exp(logits.T)/torch.exp(logits).sum(axis=1)).T\n",
    "    log_probs = torch.log(probs)\n",
    "    ce_loss = -(weights*log_probs*targets_one_hot).sum(axis=1).mean()\n",
    "    loss = ce_loss - ((mu - lam*V)*mask.flatten()).sum()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    lam = trial.suggest_float(\"lam\", 1e-3, 0.05)\n",
    "    mu = trial.suggest_float(\"mu\", 1e-3, 0.05)\n",
    "\n",
    "    hidden_channels_1 = trial.suggest_int(\"hidden_channels_1\", 100, 250)\n",
    "    hidden_channels_2 = trial.suggest_int(\"hidden_channels_2\", 100, 250)\n",
    "\n",
    "    num_layers_1 = trial.suggest_int(\"num_layers_1\", 1, 3)\n",
    "    num_layers_2 = trial.suggest_int(\"num_layers_2\", 1, 3)\n",
    "\n",
    "    dropout_1 = trial.suggest_float(\"dropout_1\", 0, 0.05)\n",
    "    dropout_2 = trial.suggest_float(\"dropout_2\", 0, 0.05)\n",
    "\n",
    "    weight_decay_1 = trial.suggest_float(\"weight_decay_1\", 1e-3, 0.05)\n",
    "    weight_decay_2 = trial.suggest_float(\"weight_decay_2\", 1e-3, 0.05)\n",
    "\n",
    "    m1 = model_1(\n",
    "        in_channels=-1,\n",
    "        hidden_channels=hidden_channels_1,\n",
    "        num_layers=num_layers_1,\n",
    "        dropout=dropout_1,\n",
    "        out_channels=1 #applied a linear layer to get out channels to 1\n",
    "    )\n",
    "\n",
    "    m2 = model_2(\n",
    "        in_channels=-1, \n",
    "        out_channels=K, \n",
    "        hidden_channels=hidden_channels_2,\n",
    "        num_layers=num_layers_2,\n",
    "        dropout=dropout_2,\n",
    "    )\n",
    "\n",
    "    optimizer_1 = torch.optim.SGD(m1.parameters(), lr=lr, weight_decay=weight_decay_1)\n",
    "    optimizer_2 = torch.optim.SGD(m2.parameters(), lr=lr, weight_decay=weight_decay_2)\n",
    "\n",
    "\n",
    "    m1.train()\n",
    "    m2.train()\n",
    "    for epoch in range(N_epochs_H):\n",
    "        optimizer_1.zero_grad()     \n",
    "        optimizer_2.zero_grad()     \n",
    "\n",
    "        loss = 0\n",
    "\n",
    "        for data in hparam_train_data:\n",
    "            pred1 = m1(\n",
    "                x=data.x.to(device),\n",
    "                edge_index=data.edges.to(device)\n",
    "            )\n",
    "\n",
    "            mask = F.sigmoid(pred1)\n",
    "\n",
    "            pred2 = m2(\n",
    "                x=data.x.to(device),\n",
    "                edge_index=data.edges.to(device)\n",
    "            )\n",
    "\n",
    "            weight = torch.bincount(data.k_labels)\n",
    "            weight = weight/weight.sum()\n",
    "\n",
    "            loss += loss_func(\n",
    "                logits=pred2,\n",
    "                target=data.k_labels.to(device),\n",
    "                V = data.V.to(device),\n",
    "                mask=mask,\n",
    "                weights=torch.tensor([1 for i in range(K)]),\n",
    "                lam = lam,\n",
    "                mu = mu\n",
    "            )\n",
    "\n",
    "        loss /= len(hparam_train_data) \n",
    "        loss.backward()\n",
    "        optimizer_1.step()\n",
    "        optimizer_2.step()\n",
    "\n",
    "    test_gap = 0\n",
    "    m1.eval()\n",
    "    m2.eval()\n",
    "    for data in hparam_val_data:\n",
    "        pred1 = m1(\n",
    "            x=data.x.to(device),\n",
    "            edge_index=data.edges.to(device)\n",
    "        )\n",
    "\n",
    "        mask = F.sigmoid(pred1)\n",
    "\n",
    "        pred2 = m2(\n",
    "            x=data.x.to(device),\n",
    "            edge_index=data.edges.to(device)\n",
    "        )\n",
    "\n",
    "        # weight = torch.bincount(data.k_labels)\n",
    "        # weight = weight/weight.sum()\n",
    "\n",
    "        # test_loss += loss_func(\n",
    "        #     logits=pred2,\n",
    "        #     target=data.k_labels.to(device),\n",
    "        #     V = data.V.to(device),\n",
    "        #     mask=mask,\n",
    "        #     weights=torch.tensor([1 for i in range(K)]),\n",
    "        #     lam = lam,\n",
    "        #     mu = mu\n",
    "        # )\n",
    "        pred_k = F.softmax(pred2, dim=1).argmax(axis=1)\n",
    "        filt = mask > 0.5\n",
    "\n",
    "        count = 1*K\n",
    "        for i in range(len(filt)):\n",
    "            if filt[i]: \n",
    "                pred_k[i] = count\n",
    "                count += 1\n",
    "        \n",
    "\n",
    "        gap, error = calculate_gap(data.P, data.R, data.V, pred_k, K, device='cpu')\n",
    "        test_gap += gap\n",
    "\n",
    "    test_gap /= len(hparam_val_data)\n",
    "\n",
    "    return test_gap\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "best_params = study.best_params\n",
    "\n",
    "print(study.best_value)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
